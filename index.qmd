---
title: "Lab: PDF Data"
author: "Dominic Sander"
format: html
number-sections: true
number-depth: 2
---

::: callout
You can see the purpose of this assignment as well as the skills and knowledge you should be using and acquiring, in the [Transparency in Learning and Teaching (TILT)](tilt.qmd) document in this repository. The TILT document also contains a checklist for self-reflection that will provide some guidance on how the assignment will be graded.
:::

# Data Source

The University of Nebraska publishes the operating budgets by department on an annual basis on [the UN System business and finance office website](https://nebraska.edu/offices-policies/business-finance/budget-and-planning), with [an archive page that contains budgets from previous fiscal years](https://nebraska.edu/offices-policies/business-finance/budget-and-planning/archive).

With impending system-wide budget cuts, our goal is to extract salary data as well as job position data, to determine how much of the cost growth is attributable to growth in administrator salaries, faculty salaries, staff salaries, and other costs.

I have preemptively included 4 budget reports in this repository, spaced at 5 year intervals, but you are welcome to include more years if you would like to do so. The budget reports are lengthy (each report is between 1350 and 1500 pages, and that is just for city campus -- it does not include IANR, the law school, the dental college, etc.).

# Warming Up

## PDF Format

What type of PDF files are these? Based on the format, what would you have to do to process the PDFs and extract text and/or tabular information (in broad terms)?

```{r}
library(pdftools)
library(stringr)
Sys.setenv(JAVA_HOME="C:/Users/Dominic Sander/AppData/Local/R/win-library/4.5/rJava/libs/x64/rJava.dll")
library(rJava)
library(tabulapdf)

pdf_info("unl-department-budget-2010-2011-pt1.pdf")$version
pdf_text("unl-department-budget-2010-2011-pt1.pdf") |>
  str_split("\n") |>
  unlist() |>
  head()

```

Above is code that extracts text from the 2010-2011 operating budget, meaning this is not a raster PDF. When just scrolling through the PDF, I found that I was able to highlight all data on the sheet. This makes me assume it is a text-based PDF. I am also going to assume all other data files for other years in the exact same format because that's how they appear at first glance. I would double check my pdfs with the code above to make sure I get a text output. Then I could use the tabula package and try to create a function to extract the text data based on page number. I'd take this output and create tibbles that would correspond that the tables in the data I want to recreate.

------------------------------------------------------------------------

## PDF Structure

Take a look at the provided PDFs in your default PDF viewer (acrobat, reader, chrome, xPDF, etc). Do they have a consistent structure across years? Across departments? Make a list of at least 3-5 problems you expect to have to overcome if you scrape data from the PDFs. Include screenshots where it is relevant to do so (similar to Fig 34.4 in the textbook), and make sure your images are included using appropriate markdown syntax, captions, and hyperlinks. Discuss how you might overcome these problems and why the PDF format leads to processing challenges.

|  |
|------------------------------------------------------------------------|
| From what I see, the five PDFs appear to share the same format for most of the data. |
| 1\. The first big issue to deal with is the fact that the 2010-2011 budget is split up into two different documents. I'd likely have to combine them to get them into a similar format to the other three. |
| 2\. While the general layout of the PDFs is similar, there are still variations within those PDFs that may make creating tabular data difficult. For example, not every person employed by UNL is faculty, so they may not get benefits like others. Also, certain sub-programs have multiple employees while others only have one, meaning the table format is going to be different between those pages. There are different strategies in the book I plan on utilizing if needed. |
| 3\. I'm not sure if this will be an issue or not, but the three newer PDFs all have the University of Nebraska script logo on the first page. It's not at all important to what we want to do, but I am worried it may cause issues given that it is an image (the only image I can find on any of the PDFs). |
| 4\. There are many pages that are generally arranged in a table, but have some inputs below them that fall between lines which could be an issue. |

------------------------------------------------------------------------

![This screenshot shows an average page in the 2015-2016 budget report.](images/Screenshot 2025-10-07 120924-01.png)

![This screenshot shows an average page in the 2025-2026 annual budget report.](images/Screenshot 2025-10-07 121021.png)

While there are a few differences in the screenshots above, the general layout of the two reports is the same. The columns have all the same labels, and the rows are information about the staff member. The 2015-2016 budget doesn't have a benefits sub-column in this example, but it does in other cases. The layout of that column could cause issues since there's two different types of observations being measured. We can also see in the examples above the Description, Subtotal, and Title columns overlap which may cause issues when using tabulapdf and separating the columns. We should have some ways around it, but they'll be a pain for sure.

![Here is the image page at the beginning of the document. Since there is no important information on this page, I'm assuming we're able to remove it in it's entirety and have no issues. I will keep my eye on it just in case.](images/Screenshot 2025-10-09 112328.png)

## Plan of Attack

What strategy would you use to read in the budget data to minimize the amount of post-processing you need to do? Explain your reasoning.

------------------------------------------------------------------------

> I would try using pdf_text, map_dfr, and extract_tables to try to get the data into as clean of a format as possible. I'd also create a variable called "page numbers."

> Using the functions above, I'd hopefully be able to create an output of tables that look the way I want them to. If it doesn't work out that way, I would (maybe) have the skills to use locate_areas to extract the data correctly. Page numbers would also allow me to cut off the beginning pages that don't include any important data, as well as the alphabetical listing of staff at the end of the document. That would allow me to make less changes after-the-fact in my data.

------------------------------------------------------------------------

## Acquiring Metadata

Use a PDF library to programmatically examine each PDF. Use a functional approach, and organize the metadata in a table, with one row per file. Do you notice any anomalies or unfamiliar metadata components which might be important? Propose a possible hypothesis for any anomalies you discover, and research/explain any unfamiliar terms in the metadata that you identified.

------------------------------------------------------------------------

```{r}
meta <- pdf_text("unl-department-budget-2010-2011-pt1.pdf")

```

------------------------------------------------------------------------

> Your response to open-ended questions goes here

------------------------------------------------------------------------

## Anomalies and Strategy Adjustments

Considering what you discovered in the previous step, do you need to adjust your strategy for reading in the data? Why or why not? Investigate any differences in metadata values across files, and determine whether or not the variation(s) may pose problems for your analysis.

------------------------------------------------------------------------

```{r}

```

------------------------------------------------------------------------

> Your response to open-ended questions goes here

------------------------------------------------------------------------

# Extracting the Text

Now that you've examined the metadata and prepared a strategy, let's see if we can extract the text from each budget report.

## Identify Relevant Pages

Develop a function that takes the path to a PDF file and identifies which pages have tabular salary data on them (e.g. get a range of pages with the salary information). Use your function to create a table with columns `file_name`, `page_start`, and `page_end`.

------------------------------------------------------------------------

> Code Chunk

------------------------------------------------------------------------

## Read in Relevant Text

Develop a function `read_salary_data(file, start, end)` which will read in all of the salary data from the pages with tables, using the 2025-2026 salary report as a guide. You should not generalize to other years yet. Use the `pdf_text` function in `tabulapdf` (R) or the `read_pdf` function in the `tabula-py` package (python).

------------------------------------------------------------------------

> Code Chunk

------------------------------------------------------------------------

## Plan your Approach

What processing steps would you use to get the text vectors from this function into a table? Make a detailed list of the necessary steps. Are there any steps you do not think will be consistently successful or generalizable? Is there information your steps sacrifice to read things in cleanly?

------------------------------------------------------------------------

> Your answer should include an ordered list of steps (indent with at least 2 spaces to form a nested list, if necessary), as well as a response to the open-ended questions at the end.

------------------------------------------------------------------------

## Would Coordinates Help?

There are other functions in the tabula software which provide the coordinates of each piece of text. How might this make it easier to ensure tables are read in correctly?

------------------------------------------------------------------------

> Your answer

------------------------------------------------------------------------

## Explore Package Documentation

Find a function that will provide coordinates for each text component, and write out the steps you might use to convert this data into a clean tabular format. What challenges will you face?

------------------------------------------------------------------------

> Your answer should include an ordered list of steps (indent with at least 2 spaces to form a nested list, if necessary), as well as a response to the open-ended question at the end.

------------------------------------------------------------------------

## A Classical Problem

Using either approach, get the salary data for all individuals in the Classics department, across all 4 reports (this should require reading in about 2 pages from each report). Plot the salaries of each individual. Generate a second plot of the total budget for the classics department, split by faculty, administration (the chair), and staff (including student workers. What do you notice?

Your answer should address some of the following questions:

-   How has the budget for Classics changed over the last 15 years?
-   How has the proportional allocation of salaries to faculty, staff, and administration changed?
-   What do you think is driving that change?

Your plots must include appropriate titles and legends, and be well constructed using an appropriate mapping. Each plot should be accompanied by a 2-4 sentence description.

------------------------------------------------------------------------

> Code chunk(s)

------------------------------------------------------------------------

> Overall observations

------------------------------------------------------------------------

## Quality Control

If you were to process the full set of faculty salary data across all departments, what quality control measures would you use to ensure your functions functioned as expected? Explain your answer and your reasoning.

------------------------------------------------------------------------

> Your answer and explanation

------------------------------------------------------------------------
